{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a502fdf6-df55-440b-bf15-28f0d4a89741",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tarfile\n",
    "import spacy\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d734f545-4c97-4dbf-b961-fca07370a8d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"data/obamacare_19_23.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5739530f-2a4b-468e-b587-22284991a2b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tweets df is(36724, 3) ; Size of tweets df is 110172\n",
      "Columns areIndex(['Id', 'Date', 'Text'], dtype='object')\n",
      "Unique tweets are 14826\n"
     ]
    }
   ],
   "source": [
    "#Exploring dataset characteristics\n",
    "print(f\"Shape of tweets df is{tweets.shape}\",f\"; Size of tweets df is {tweets.size}\")\n",
    "print(f\"Columns are{tweets.columns}\")\n",
    "print(f\"Unique tweets are {tweets['Text'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "122ce4f4-dd14-4817-8898-d8721ccdff36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique dates for tweets are 1421\n",
      "0    2023-03-31\n",
      "1    2023-03-31\n",
      "2    2023-03-31\n",
      "Name: Date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Exploring most common periods of tweets\n",
    "print(f\"Unique dates for tweets are {tweets['Date'].nunique()}\")\n",
    "print(tweets['Date'].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa06effb-f5ab-4ef3-9c41-8c0f4cff1412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Month  Year  count\n",
      "28      7  2020   7341\n",
      "44     11  2020   3573\n",
      "36      9  2020   2365\n",
      "40     10  2020   2322\n",
      "4       1  2023   1981\n",
      "1       1  2020   1505\n",
      "32      8  2020   1319\n",
      "15      4  2019   1219\n",
      "11      3  2020   1132\n",
      "10      3  2019    964\n",
      "3       1  2022    758\n",
      "13      3  2022    715\n",
      "19      5  2019    685\n",
      "20      5  2020    679\n",
      "24      6  2020    669\n",
      "6       2  2020    655\n",
      "12      3  2021    550\n",
      "25      6  2021    506\n",
      "27      7  2019    500\n",
      "2       1  2021    487\n",
      "42     10  2022    463\n",
      "18      4  2022    459\n",
      "0       1  2019    437\n",
      "7       2  2021    436\n",
      "14      3  2023    410\n",
      "43     11  2019    406\n",
      "16      4  2020    399\n",
      "47     12  2019    334\n",
      "34      8  2022    297\n",
      "23      6  2019    296\n",
      "31      8  2019    247\n",
      "37      9  2021    239\n",
      "39     10  2019    226\n",
      "38      9  2022    224\n",
      "49     12  2021    203\n",
      "5       2  2019    192\n",
      "30      7  2022    171\n",
      "35      9  2019    168\n",
      "48     12  2020    153\n",
      "9       2  2023    141\n",
      "46     11  2022    123\n",
      "22      5  2022    112\n",
      "17      4  2021    112\n",
      "45     11  2021    105\n",
      "33      8  2021     83\n",
      "26      6  2022     80\n",
      "29      7  2021     76\n",
      "41     10  2021     68\n",
      "8       2  2022     64\n",
      "50     12  2022     40\n",
      "21      5  2021     35\n"
     ]
    }
   ],
   "source": [
    "#Analysis of tweets published by month/year\n",
    "\n",
    "# Convert 'date' column to datetime object\n",
    "tweets['Date'] = pd.to_datetime(tweets['Date'])\n",
    "\n",
    "# Extract month and year from 'date' column\n",
    "tweets['Month'] = tweets['Date'].dt.month\n",
    "tweets['Year'] = tweets['Date'].dt.year\n",
    "\n",
    "# Group by month and year and count the number of tweets\n",
    "tweet_count = tweets.groupby(['Month', 'Year'])['Text'].count().reset_index()\n",
    "\n",
    "# Rename 'text' column to 'count'\n",
    "tweet_count = tweet_count.rename(columns={'Text': 'count'})\n",
    "tweet_count = tweet_count.sort_values(by='count', ascending=False)\n",
    "\n",
    "# Print the resulting table\n",
    "print(tweet_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc12d6f3-d42e-4e71-af6b-f1e471701143",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Sanjeev\n",
      "[nltk_data]     HRSCM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Sanjeev\n",
      "[nltk_data]     HRSCM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Now moving to analysis of tweets\n",
    "\n",
    "#Cleaning text and generating tokens\n",
    "nltk.download('stopwords') \n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tweet_text = tweets.loc[:,'Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f7c642c-fae2-4754-be4d-eaf1156bd02a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Function to clean text, create tokens\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # Remove non-alphanumeric characters except # and @\n",
    "    text = re.sub(r'[^\\w\\s#@]', '', text)\n",
    "    # Tokenize and lemmatize\n",
    "    # Adding a pattern to ensure handles and hashtags remain intact; eg: #obama will not be split into # and obama\n",
    "    pattern = r'\\w+|#\\w+|@\\w+'\n",
    "    tokens = [lemmatizer.lemmatize(token.lower()) for token in regexp_tokenize(text, pattern)]\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "all_tokens = []\n",
    "all_hashtags = []\n",
    "all_handles = []\n",
    "\n",
    "for tokens in tweet_text.apply(clean_text):\n",
    "    for token in tokens:\n",
    "        if token.startswith('#'):\n",
    "            all_hashtags.append(token)\n",
    "        elif token.startswith('@'):\n",
    "            all_handles.append(token)\n",
    "        else:\n",
    "            all_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a76ee5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating the above but modifying the original tweets dataset for exporting\n",
    "\n",
    "# Create new columns for tokens, hashtags, and handles\n",
    "tweets['Tokens'] = tweets['Text'].apply(lambda x: clean_text(x))\n",
    "tweets['Hashtags'] = tweets['Tokens'].apply(lambda x: [token for token in x if token.startswith('#')])\n",
    "tweets['Handles'] = tweets['Tokens'].apply(lambda x: [token for token in x if token.startswith('@')])\n",
    "\n",
    "# Export the modified dataset to a CSV file\n",
    "tweets.to_csv('data/tokenized_tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cbeb87bc-b534-49b9-939c-718b152d2126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Count frequency of relevant tokens, hashtags, and handles\n",
    "token_counts = Counter(all_tokens)\n",
    "hashtag_counts = Counter(all_hashtags)\n",
    "handle_counts = Counter(all_handles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "276da11e-c398-41e9-b4cc-b4f3d8655b41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a table of all tokens, hashtags and handles with frequency\n",
    "twitt_desc = [('token', token, count) for token, count in token_counts.items()]\n",
    "twitt_desc += [('hashtag', hashtag, count) for hashtag, count in hashtag_counts.items()]\n",
    "twitt_desc += [('handle', handle, count) for handle, count in handle_counts.items()]\n",
    "twitt_table = pd.DataFrame(table_data, columns=['Type', 'Value', 'Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "400b1117-f094-49a0-9714-eaaf006f92ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14294</th>\n",
       "      <td>hashtag</td>\n",
       "      <td>#aca</td>\n",
       "      <td>5280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14293</th>\n",
       "      <td>hashtag</td>\n",
       "      <td>#obamacare</td>\n",
       "      <td>5136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14320</th>\n",
       "      <td>hashtag</td>\n",
       "      <td>#healthcare</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14696</th>\n",
       "      <td>hashtag</td>\n",
       "      <td>#scotus</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14791</th>\n",
       "      <td>hashtag</td>\n",
       "      <td>#trump</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14599</th>\n",
       "      <td>hashtag</td>\n",
       "      <td>#covid19</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14302</th>\n",
       "      <td>hashtag</td>\n",
       "      <td>#affordablecareact</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14319</th>\n",
       "      <td>hashtag</td>\n",
       "      <td>#medicaid</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14639</th>\n",
       "      <td>hashtag</td>\n",
       "      <td>#medicare4all</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14615</th>\n",
       "      <td>hashtag</td>\n",
       "      <td>#preexistingconditions</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Type                   Value  Frequency\n",
       "14294  hashtag                    #aca       5280\n",
       "14293  hashtag              #obamacare       5136\n",
       "14320  hashtag             #healthcare        845\n",
       "14696  hashtag                 #scotus        540\n",
       "14791  hashtag                  #trump        540\n",
       "14599  hashtag                #covid19        539\n",
       "14302  hashtag      #affordablecareact        533\n",
       "14319  hashtag               #medicaid        310\n",
       "14639  hashtag           #medicare4all        295\n",
       "14615  hashtag  #preexistingconditions        275"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 most occuring hashtags\n",
    "twitt_table.loc[(twitt_table.loc[:,'Type'] == 'hashtag'),:].sort_values(by='Frequency', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8c147ad9-e21c-476c-8505-1fb72ea2c17a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18123</th>\n",
       "      <td>handle</td>\n",
       "      <td>@speakerpelosi</td>\n",
       "      <td>3832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20928</th>\n",
       "      <td>handle</td>\n",
       "      <td>@realdonaldtrump</td>\n",
       "      <td>2515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17959</th>\n",
       "      <td>handle</td>\n",
       "      <td>@barackobama</td>\n",
       "      <td>2474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18133</th>\n",
       "      <td>handle</td>\n",
       "      <td>@nytimes</td>\n",
       "      <td>1639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23223</th>\n",
       "      <td>handle</td>\n",
       "      <td>@ambassadorrice</td>\n",
       "      <td>776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18090</th>\n",
       "      <td>handle</td>\n",
       "      <td>@deanobeidallah</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17965</th>\n",
       "      <td>handle</td>\n",
       "      <td>@joebiden</td>\n",
       "      <td>695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17964</th>\n",
       "      <td>handle</td>\n",
       "      <td>@gop</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22161</th>\n",
       "      <td>handle</td>\n",
       "      <td>@sebelius</td>\n",
       "      <td>633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18723</th>\n",
       "      <td>handle</td>\n",
       "      <td>@ewarren</td>\n",
       "      <td>612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Type             Value  Frequency\n",
       "18123  handle    @speakerpelosi       3832\n",
       "20928  handle  @realdonaldtrump       2515\n",
       "17959  handle      @barackobama       2474\n",
       "18133  handle          @nytimes       1639\n",
       "23223  handle   @ambassadorrice        776\n",
       "18090  handle   @deanobeidallah        738\n",
       "17965  handle         @joebiden        695\n",
       "17964  handle              @gop        679\n",
       "22161  handle         @sebelius        633\n",
       "18723  handle          @ewarren        612"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 most occuring handles\n",
    "twitt_table.loc[(twitt_table.loc[:,'Type'] == 'handle'),:].sort_values(by='Frequency', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "22be178b-84b9-490f-a9b2-1bb4a6555bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Value</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>token</td>\n",
       "      <td>rt</td>\n",
       "      <td>24491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>token</td>\n",
       "      <td>care</td>\n",
       "      <td>12597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>token</td>\n",
       "      <td>health</td>\n",
       "      <td>11342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>token</td>\n",
       "      <td>obamacare</td>\n",
       "      <td>9289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>token</td>\n",
       "      <td>trump</td>\n",
       "      <td>8945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>token</td>\n",
       "      <td>amp</td>\n",
       "      <td>7241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>token</td>\n",
       "      <td>aca</td>\n",
       "      <td>7178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>token</td>\n",
       "      <td>woman</td>\n",
       "      <td>6448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>token</td>\n",
       "      <td>president</td>\n",
       "      <td>5501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>token</td>\n",
       "      <td>take</td>\n",
       "      <td>5496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type      Value  Frequency\n",
       "57    token         rt      24491\n",
       "36    token       care      12597\n",
       "6     token     health      11342\n",
       "43    token  obamacare       9289\n",
       "84    token      trump       8945\n",
       "277   token        amp       7241\n",
       "52    token        aca       7178\n",
       "1914  token      woman       6448\n",
       "188   token  president       5501\n",
       "126   token       take       5496"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 most occuring tokens\n",
    "twitt_table.loc[(twitt_table.loc[:,'Type'] == 'token'),:].sort_values(by='Frequency', ascending=False).head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
