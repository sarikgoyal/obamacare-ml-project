{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import random\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I don't think you guys would need to run this at all\n",
    "# import os\n",
    "# os.getcwd()\n",
    "# os.chdir('d:\\\\Harris Course work\\\\MLPP\\\\ml_proj\\\\obamacare-ml-project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting file path and chunk size\n",
    "file_path = 'data/yelp_academic_dataset_review.json'\n",
    "chunk_size = 1000\n",
    "\n",
    "#Calculating size of the dataset\n",
    "with open(file_path, 'r', encoding='utf-8') as f:\n",
    "    num_records = sum(1 for line in f)\n",
    "\n",
    "#Generating a random set of indices to subset\n",
    "subset_size = int(num_records * 0.1)  # load 10% of the records\n",
    "indices = random.sample(range(num_records), subset_size)\n",
    "\n",
    "# Loading the rows corresponding to the randomly generated indices\n",
    "chunks = []\n",
    "json_reader = pd.read_json(file_path, lines=True, chunksize=chunk_size)\n",
    "for chunk in json_reader:\n",
    "    filtered_chunk = chunk[chunk.index.isin(indices)]\n",
    "    if not filtered_chunk.empty:\n",
    "        chunks.append(filtered_chunk)\n",
    "\n",
    "# concatenate the chunks into a single DataFrame\n",
    "df = pd.concat(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>XW_LfMv0fV21l9c6xQd_lw</td>\n",
       "      <td>9OAtfnWag-ajVxRbUTGIyg</td>\n",
       "      <td>lj-E32x9_FA7GmUrBGBEWg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Love going here for happy hour or dinner!  Gre...</td>\n",
       "      <td>2014-06-27 22:44:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>oyaMhzBSwfGgemSGuZCdwQ</td>\n",
       "      <td>Dd1jQj7S-BFGqRbApFzCFw</td>\n",
       "      <td>YtSqYv1Q_pOltsVPSx54SA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Tremendous service (Big shout out to Douglas) ...</td>\n",
       "      <td>2013-06-24 11:21:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Xs8Z8lmKkosqW5mw_sVAoA</td>\n",
       "      <td>IQsF3Rc6IgCzjVV9DE8KXg</td>\n",
       "      <td>eFvzHawVJofxSnD7TgbZtg</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>My absolute favorite cafe in the city. Their b...</td>\n",
       "      <td>2014-11-12 15:30:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>qS6kE7CDoDagyPZwmueJaQ</td>\n",
       "      <td>zoBajEyVA0z4IjbFsMJksg</td>\n",
       "      <td>c-IgS6Pk6vMyax7Rbr38eA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Went for lunch. Beef brisket sandwich was awes...</td>\n",
       "      <td>2015-06-08 19:45:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>DyrAIuKl60j_X8Yrrv-kpg</td>\n",
       "      <td>mNsVyC9tQVYtzLOCbh2Piw</td>\n",
       "      <td>MWmXGQ98KbRo3vsS5nZhMA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I recently had dinner here with my wife over t...</td>\n",
       "      <td>2014-10-27 02:47:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 review_id                 user_id             business_id  \\\n",
       "12  XW_LfMv0fV21l9c6xQd_lw  9OAtfnWag-ajVxRbUTGIyg  lj-E32x9_FA7GmUrBGBEWg   \n",
       "16  oyaMhzBSwfGgemSGuZCdwQ  Dd1jQj7S-BFGqRbApFzCFw  YtSqYv1Q_pOltsVPSx54SA   \n",
       "19  Xs8Z8lmKkosqW5mw_sVAoA  IQsF3Rc6IgCzjVV9DE8KXg  eFvzHawVJofxSnD7TgbZtg   \n",
       "25  qS6kE7CDoDagyPZwmueJaQ  zoBajEyVA0z4IjbFsMJksg  c-IgS6Pk6vMyax7Rbr38eA   \n",
       "28  DyrAIuKl60j_X8Yrrv-kpg  mNsVyC9tQVYtzLOCbh2Piw  MWmXGQ98KbRo3vsS5nZhMA   \n",
       "\n",
       "    stars  useful  funny  cool  \\\n",
       "12      4       0      0     0   \n",
       "16      5       0      0     0   \n",
       "19      5       0      0     0   \n",
       "25      4       0      0     0   \n",
       "28      5       1      0     0   \n",
       "\n",
       "                                                 text                date  \n",
       "12  Love going here for happy hour or dinner!  Gre... 2014-06-27 22:44:01  \n",
       "16  Tremendous service (Big shout out to Douglas) ... 2013-06-24 11:21:25  \n",
       "19  My absolute favorite cafe in the city. Their b... 2014-11-12 15:30:27  \n",
       "25  Went for lunch. Beef brisket sandwich was awes... 2015-06-08 19:45:48  \n",
       "28  I recently had dinner here with my wife over t... 2014-10-27 02:47:28  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    0.462854\n",
       "4    0.208492\n",
       "1    0.152344\n",
       "3    0.098301\n",
       "2    0.078008\n",
       "Name: stars, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,'stars'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews = df.loc[:, ['text','stars', 'useful','funny','cool']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(699028, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Love going here for happy hour or dinner!  Gre...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Tremendous service (Big shout out to Douglas) ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>My absolute favorite cafe in the city. Their b...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Went for lunch. Beef brisket sandwich was awes...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I recently had dinner here with my wife over t...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  stars  useful  funny  \\\n",
       "12  Love going here for happy hour or dinner!  Gre...      4       0      0   \n",
       "16  Tremendous service (Big shout out to Douglas) ...      5       0      0   \n",
       "19  My absolute favorite cafe in the city. Their b...      5       0      0   \n",
       "25  Went for lunch. Beef brisket sandwich was awes...      4       0      0   \n",
       "28  I recently had dinner here with my wife over t...      5       1      0   \n",
       "\n",
       "    cool  \n",
       "12     0  \n",
       "16     0  \n",
       "19     0  \n",
       "25     0  \n",
       "28     0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\soumy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\soumy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\soumy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing and lemmatizing: I had some issue switching to Eshan's branch.\n",
    "# Please edit if I missed a step\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-processing strings\n",
    "yelp_reviews.loc[:,'text'] = yelp_reviews.loc[:,'text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing punctuation\n",
    "punc = r'[{}]+'.format(string.punctuation)\n",
    "yelp_reviews.loc[:,'text'] = yelp_reviews.loc[:,'text'].apply(lambda x: re.sub(punc,'',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews.loc[:,'text'] = yelp_reviews.loc[:,'text'] .apply(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "yelp_reviews.loc[:,'text'] = yelp_reviews.loc[:,'text'].apply(lambda x: [i for i in x if i not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "yelp_reviews.loc[:,'text'] = yelp_reviews.loc[:,'text'].apply(lambda x: [lemmatizer.lemmatize(i) for i in x])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model 1: Binary Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[love, going, happy, hour, dinner, great, pati...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[tremendous, service, big, shout, douglas, com...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[absolute, favorite, cafe, city, black, white,...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[went, lunch, beef, brisket, sandwich, awesome...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[recently, dinner, wife, weekend, could, pleas...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  stars  useful  funny  \\\n",
       "12  [love, going, happy, hour, dinner, great, pati...      4       0      0   \n",
       "16  [tremendous, service, big, shout, douglas, com...      5       0      0   \n",
       "19  [absolute, favorite, cafe, city, black, white,...      5       0      0   \n",
       "25  [went, lunch, beef, brisket, sandwich, awesome...      4       0      0   \n",
       "28  [recently, dinner, wife, weekend, could, pleas...      5       1      0   \n",
       "\n",
       "    cool  \n",
       "12     0  \n",
       "16     0  \n",
       "19     0  \n",
       "25     0  \n",
       "28     0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_useful = pd.crosstab(yelp_reviews.loc[:,'useful'], yelp_reviews.loc[:,'stars'])\n",
    "table_useful"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useful has 134 unique values. 91% of the data is restricted to values of useful < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews.loc[:,'useful'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_funny = pd.crosstab(yelp_reviews.loc[:,'funny'], yelp_reviews.loc[:,'stars'])\n",
    "table_funny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews.loc[:,'funny'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "84% of data is just the 0 label. 100 items but very little variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_cool = pd.crosstab(yelp_reviews.loc[:,'cool'], yelp_reviews.loc[:,'stars'])\n",
    "table_cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews.loc[:,'cool'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "76% of data is label 0 and 14% is label 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression- Part 1**\n",
    "starsV1:\n",
    "Creating two classes:\n",
    "    labels 1-3 = bad (0)\n",
    "    labels 4-5 = good (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making stars dichotomous with threshold of 3\n",
    "yelp_reviews.loc[:, 'starsv1'] = 1\n",
    "yelp_reviews.loc[yelp_reviews.loc[:,'stars'] < 4, 'starsv1'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.671346\n",
       "0    0.328654\n",
       "Name: starsv1, dtype: float64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews.loc[:,'starsv1'].value_counts(normalize=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Case 2: Creating 3 classes\n",
    "starsV2:\n",
    "    labels 1-2 = bad (0)\n",
    "    Label 3 = Neutral (1)\n",
    "    labels 4-5 = good (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews.loc[:, 'starsv2'] = 2\n",
    "yelp_reviews.loc[yelp_reviews.loc[:,'stars'] < 3, 'starsv2'] = 0\n",
    "yelp_reviews.loc[yelp_reviews.loc[:,'stars'] == 3, 'starsv2'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>starsv1</th>\n",
       "      <th>starsv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[love, going, happy, hour, dinner, great, pati...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[tremendous, service, big, shout, douglas, com...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[absolute, favorite, cafe, city, black, white,...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[went, lunch, beef, brisket, sandwich, awesome...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[recently, dinner, wife, weekend, could, pleas...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  stars  useful  funny  \\\n",
       "12  [love, going, happy, hour, dinner, great, pati...      4       0      0   \n",
       "16  [tremendous, service, big, shout, douglas, com...      5       0      0   \n",
       "19  [absolute, favorite, cafe, city, black, white,...      5       0      0   \n",
       "25  [went, lunch, beef, brisket, sandwich, awesome...      4       0      0   \n",
       "28  [recently, dinner, wife, weekend, could, pleas...      5       1      0   \n",
       "\n",
       "    cool  starsv1  starsv2  \n",
       "12     0        1        2  \n",
       "16     0        1        2  \n",
       "19     0        1        2  \n",
       "25     0        1        2  \n",
       "28     0        1        2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For dichotomous data in starsV1\n",
    "dict_pos_v1 = {}\n",
    "dict_neg_v1 = {}\n",
    "for list_w, star in zip(yelp_reviews.loc[:,'text'], yelp_reviews.loc[:,'starsv1']):\n",
    "    if  star == 1:\n",
    "        for word in list_w:\n",
    "            if word not in dict_pos_v1:\n",
    "                dict_pos_v1[word] = 0\n",
    "            dict_pos_v1[word] += 1\n",
    "    else:\n",
    "        for word in list_w:\n",
    "            if word not in dict_neg_v1:\n",
    "                dict_neg_v1[word] = 0\n",
    "            dict_neg_v1[word] += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For data in starsV2\n",
    "dict_pos_v2 = {}\n",
    "dict_neg_v2 = {}\n",
    "dict_neut_v2 ={}\n",
    "for list_w, star in zip(yelp_reviews.loc[:,'text'], yelp_reviews.loc[:,'starsv2']):\n",
    "    if  star == 2:\n",
    "        for word in list_w:\n",
    "            if word not in dict_pos_v2:\n",
    "                dict_pos_v2[word] = 0\n",
    "            dict_pos_v2[word] += 1\n",
    "    elif star == 0:\n",
    "        for word in list_w:\n",
    "            if word not in dict_neg_v2:\n",
    "                dict_neg_v2[word] = 0\n",
    "            dict_neg_v2[word] += 1\n",
    "    else:\n",
    "        for word in list_w:\n",
    "            if word not in dict_neut_v2:\n",
    "                dict_neut_v2[word] = 0\n",
    "            dict_neut_v2[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumulative_count(list_tokens, pos_dict, neg_dict, neut_dict = {}):\n",
    "    count_dict = {'pos':0, 'neg':0, 'neut':0}\n",
    "    for word in list_tokens:\n",
    "        if word in pos_dict:\n",
    "            count_dict['pos'] += pos_dict[word]\n",
    "        if word in neg_dict:\n",
    "            count_dict['neg'] += neg_dict[word]\n",
    "        if word in neut_dict:\n",
    "            count_dict['neut'] += neut_dict[word]    \n",
    "    return count_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews.loc[:,'cum_count_v1'] = yelp_reviews.loc[:,'text'].apply(lambda x: cumulative_count(x, dict_pos_v1, dict_neg_v1))\n",
    "yelp_reviews.loc[:,'cum_count_v2'] = yelp_reviews.loc[:,'text'].apply(lambda x: cumulative_count(x, dict_pos_v2, dict_neg_v2, dict_neut_v2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dict(dict_c, key):\n",
    "    return dict_c[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews.loc[:,'posv1'] = yelp_reviews.loc[:, 'cum_count_v1'].apply(lambda x: split_dict(x,'pos'))\n",
    "yelp_reviews.loc[:,'negv1'] = yelp_reviews.loc[:, 'cum_count_v1'].apply(lambda x: split_dict(x,'neg'))\n",
    "yelp_reviews.loc[:,'posv2'] = yelp_reviews.loc[:, 'cum_count_v2'].apply(lambda x: split_dict(x,'pos'))\n",
    "yelp_reviews.loc[:,'neutv2'] = yelp_reviews.loc[:, 'cum_count_v2'].apply(lambda x: split_dict(x,'neut'))\n",
    "yelp_reviews.loc[:,'negv2'] = yelp_reviews.loc[:, 'cum_count_v2'].apply(lambda x: split_dict(x,'neg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "yelp_reviews.drop('cum_count_v1', axis=1, inplace=True)\n",
    "yelp_reviews.drop('cum_count_v2', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>starsv1</th>\n",
       "      <th>starsv2</th>\n",
       "      <th>posv1</th>\n",
       "      <th>negv1</th>\n",
       "      <th>posv2</th>\n",
       "      <th>neutv2</th>\n",
       "      <th>negv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[love, going, happy, hour, dinner, great, pati...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>815923</td>\n",
       "      <td>373849</td>\n",
       "      <td>815923</td>\n",
       "      <td>132754</td>\n",
       "      <td>241095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[tremendous, service, big, shout, douglas, com...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>926870</td>\n",
       "      <td>513365</td>\n",
       "      <td>926870</td>\n",
       "      <td>170857</td>\n",
       "      <td>342508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[absolute, favorite, cafe, city, black, white,...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1403905</td>\n",
       "      <td>670485</td>\n",
       "      <td>1403905</td>\n",
       "      <td>232332</td>\n",
       "      <td>438153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[went, lunch, beef, brisket, sandwich, awesome...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>456859</td>\n",
       "      <td>220638</td>\n",
       "      <td>456859</td>\n",
       "      <td>94089</td>\n",
       "      <td>126549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[recently, dinner, wife, weekend, could, pleas...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1303879</td>\n",
       "      <td>684392</td>\n",
       "      <td>1303879</td>\n",
       "      <td>226474</td>\n",
       "      <td>457918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  stars  useful  funny  \\\n",
       "12  [love, going, happy, hour, dinner, great, pati...      4       0      0   \n",
       "16  [tremendous, service, big, shout, douglas, com...      5       0      0   \n",
       "19  [absolute, favorite, cafe, city, black, white,...      5       0      0   \n",
       "25  [went, lunch, beef, brisket, sandwich, awesome...      4       0      0   \n",
       "28  [recently, dinner, wife, weekend, could, pleas...      5       1      0   \n",
       "\n",
       "    cool  starsv1  starsv2    posv1   negv1    posv2  neutv2   negv2  \n",
       "12     0        1        2   815923  373849   815923  132754  241095  \n",
       "16     0        1        2   926870  513365   926870  170857  342508  \n",
       "19     0        1        2  1403905  670485  1403905  232332  438153  \n",
       "25     0        1        2   456859  220638   456859   94089  126549  \n",
       "28     0        1        2  1303879  684392  1303879  226474  457918  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp_reviews.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary Data with all Labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yelp_reviews.loc[:,['posv1', 'negv1', 'useful', 'funny', 'cool']].to_numpy()\n",
    "y = yelp_reviews.loc[:,'starsv1'].to_numpy()\n",
    "clf = LogisticRegression()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_v1 = accuracy_score(y_test, y_pred)\n",
    "precision_v1 = precision_score(y_test, y_pred, average='weighted')\n",
    "f1_v1 = f1_score(y_test, y_pred, average='weighted')\n",
    "recall_v1 = recall_score(y_test, y_pred, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8119680128177618\n",
      "Precision: 0.8079780190065572\n",
      "Recall: 0.8119680128177618\n",
      "F1 Score: 0.8079392347761343\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_v1}\")\n",
    "print(f\"Precision: {precision_v1}\")\n",
    "print(f\"Recall: {recall_v1}\")\n",
    "print(f\"F1 Score: {f1_v1}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Binary data with random forest to select important features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SelectFromModel(estimator=RandomForestClassifier())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SelectFromModel</label><div class=\"sk-toggleable__content\"><pre>SelectFromModel(estimator=RandomForestClassifier())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "SelectFromModel(estimator=RandomForestClassifier())"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection = SelectFromModel(RandomForestClassifier(n_estimators=100))\n",
    "selection.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, False, False])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selection.get_support()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from the random forest show that only the first two features i.e. posv1 and negv1 are important. Running the model again using these two features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf = yelp_reviews.loc[:,['posv1', 'negv1']].to_numpy()\n",
    "y_rf = yelp_reviews.loc[:,'starsv1'].to_numpy()\n",
    "clf_rf = LogisticRegression()\n",
    "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.2, random_state=42)\n",
    "clf_rf.fit(X_train_rf, y_train_rf)\n",
    "y_pred_rf = clf.predict(X_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_rf = accuracy_score(y_test_rf, y_pred_rf)\n",
    "precision_rf = precision_score(y_test_rf, y_pred_rf, average='weighted')\n",
    "f1_rf = f1_score(y_test_rf, y_pred_rf, average='weighted')\n",
    "recall_rf = recall_score(y_test_rf, y_pred_rf, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8119680128177618\n",
      "Precision: 0.8079780190065572\n",
      "Recall: 0.8119680128177618\n",
      "F1 Score: 0.8079392347761343\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy_rf}\")\n",
    "print(f\"Precision: {precision_rf}\")\n",
    "print(f\"Recall: {recall_rf}\")\n",
    "print(f\"F1 Score: {f1_rf}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 classes **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = yelp_reviews.loc[:,['posv2', 'neutv2', 'negv2']]\n",
    "y = yelp_reviews.loc[:,'starsv2']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(multi_class=&#x27;ovr&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(multi_class=&#x27;ovr&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(multi_class='ovr', solver='liblinear')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrm = LogisticRegression(multi_class='ovr', solver='liblinear')\n",
    "lrm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = lrm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21894,  1428,  9022],\n",
       "       [ 3615,  1888,  8347],\n",
       "       [ 5102,  2154, 86356]], dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test ,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.72      0.68      0.70     32344\\n           1       0.35      0.14      0.20     13850\\n           2       0.83      0.92      0.88     93612\\n\\n    accuracy                           0.79    139806\\n   macro avg       0.63      0.58      0.59    139806\\nweighted avg       0.76      0.79      0.77    139806\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.classification_report(y_test, yhat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the logistic regression model with two classes (0 for stars 1-3 and 1 for stars 4-5) works better as compared to the three class model. Furthermore, using the random forest model, we were able to identify the best features for our model i.e. posv1 (number of occurences of words in text in positive connotation) and negv1 (number of occurences of words in text in negative connotation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
